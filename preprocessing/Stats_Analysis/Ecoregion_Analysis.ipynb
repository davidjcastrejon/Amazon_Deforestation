{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "34ff5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import glob\n",
    "import ctypes\n",
    "import rasterio\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterio.merge import merge\n",
    "from osgeo import ogr, gdal, osr\n",
    "from multiprocessing import Pool\n",
    "from rasterio.enums import Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d1ca16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "PRODES = '/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/PRODES/prodes_amazonia_raster_2000_2022_v20231109/prodes_amazonia_raster_2000_2022_v20231109.tif'\n",
    "ecoregions_dir = '/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/Ecoregions/Brazilian_Amazon_Ecoregions'\n",
    "deforested_ecoregions = '/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/Ecoregions/Deforested_Ecoregions'\n",
    "ecoregions = [filename for filename in os.listdir(ecoregions_dir) if filename.endswith('.shp')]\n",
    "APPEARS_dir = '/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/APPEARS/EVI/2015-2023-EVI'\n",
    "csv_dir = f'/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/QGIS/Ecoregion_Analysis.csv'\n",
    "working_dir = f'/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/QGIS'\n",
    "years = [16, 17, 18, 19, 20, 21, 22]\n",
    "\n",
    "with open(csv_dir, 'a', newline='') as csv_file: \n",
    "    csv_writer = csv.writer(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "2e176aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geotransform_from_file(tif_path):\n",
    "    \"\"\"\n",
    "    Get GeoTransform information from a GeoTIFF file.\n",
    "\n",
    "    Parameters:\n",
    "    - tif_path: Path to the GeoTIFF file\n",
    "\n",
    "    Returns:\n",
    "    - geotransform: GeoTransform information as a tuple\n",
    "    \"\"\"\n",
    "    dataset = gdal.Open(tif_path)\n",
    "    geotransform = dataset.GetGeoTransform()\n",
    "    dataset = None  # Close the dataset\n",
    "    return geotransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "7002bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlon_to_pixel(lat, lon, geotransform):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert latitude and longitude to pixel coordinates in a GeoTIFF file.\n",
    "\n",
    "    Parameters:\n",
    "    - lat: Latitude\n",
    "    - lon: Longitude\n",
    "    - geotransform: GeoTransform information from the GeoTIFF file\n",
    "\n",
    "    Returns:\n",
    "    - x_pixel: Pixel x-coordinate\n",
    "    - y_pixel: Pixel y-coordinate\n",
    "    \"\"\"\n",
    "\n",
    "    # Extracting GeoTransform parameters\n",
    "    x_geo, pixel_width, _, y_geo, _, pixel_height = geotransform\n",
    "\n",
    "    # Calculating pixel coordinates\n",
    "    x_pixel = int((lon - x_geo) / pixel_width)\n",
    "    y_pixel = int((lat - y_geo) / pixel_height)\n",
    "\n",
    "    return x_pixel, y_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "39644a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_lon_from_pixel(geo_transform, col, row):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert pixel coordinates in a GeoTIFF file to latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    - column\n",
    "    - row\n",
    "    - geotransform: GeoTransform information from the GeoTIFF file\n",
    "\n",
    "    Returns:\n",
    "    - latitude\n",
    "    - longitude\n",
    "    \"\"\"\n",
    "    print(f'this is geo_transform_2: {geo_transform[2]}')\n",
    "    print(f'this is geo_transform_5: {geo_transform[5]}')\n",
    "    print(f'this is geo_transform_3: {geo_transform[3]}')\n",
    "    \n",
    "    lon = geo_transform[0] + col * geo_transform[1] + row * geo_transform[2]\n",
    "    lat = geo_transform[3] + col * geo_transform[4] + row * geo_transform[5]\n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "572031bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tiles(year):\n",
    "    # Input directory containing the TIFF files\n",
    "    if year < 10:\n",
    "        input_directory = f'/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/GFC/GFC_Tiles/200{year}_GFC_tiles'\n",
    "        output_file = f'/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/QGIS/200{year}_gfc.tif'\n",
    "    else:\n",
    "        input_directory = f'/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/GFC/GFC_Tiles/20{year}_GFC_tiles'\n",
    "        output_file = f'/Users/davidcastrejon/Documents/Amazon_Rainforest/Data/QGIS/20{year}_gfc.tif'\n",
    "\n",
    "    # Returns if output file already exists\n",
    "    if os.path.exists(output_file):\n",
    "        print(f'The GFC output file for year {year} already exists. Aborting.\\n')\n",
    "        return\n",
    "    \n",
    "    # Get a list of all TIFF files in the directory\n",
    "    input_files = glob.glob(os.path.join(input_directory, '*.tif'))\n",
    "\n",
    "    # Check if there are any TIFF files\n",
    "    if not input_files:\n",
    "        print(f'No TIFF files found in the specified directory.\\n')\n",
    "        return\n",
    "\n",
    "    # Read all input files\n",
    "    src_files_to_mosaic = [rasterio.open(file) for file in input_files]\n",
    "\n",
    "    # Merge files\n",
    "    mosaic, out_trans = merge(src_files_to_mosaic, resampling=Resampling.nearest)\n",
    "\n",
    "    # Update metadata of the output file\n",
    "    out_meta = src_files_to_mosaic[0].meta.copy()\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\", \n",
    "        \"height\": mosaic.shape[1], \n",
    "        \"width\": mosaic.shape[2], \n",
    "        \"transform\": out_trans, \n",
    "        \"dtype\": src_files_to_mosaic[0].dtypes[0],\n",
    "        \"compress\": \"lzw\"\n",
    "    })\n",
    "    \n",
    "    # Write the mosaic to the output file\n",
    "    with rasterio.open(output_file, \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "319c3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_ecoregion(shp_path, ecoregion, year):\n",
    "    if year < 10:\n",
    "        prodes_yearly = f'200{year}_prodes.tif'\n",
    "        gfc_yearly = f'200{year}_gfc.tif'\n",
    "        gfc_ecoregion = f'gfc_{ecoregion}_200{year}.tif'\n",
    "        prodes_ecoregion = f'prodes_{ecoregion}_200{year}.tif'\n",
    "    else:\n",
    "        prodes_yearly = f'20{year}_prodes.tif'\n",
    "        gfc_yearly = f'20{year}_gfc.tif'\n",
    "        gfc_ecoregion = f'gfc_{ecoregion}_20{year}.tif'\n",
    "        prodes_ecoregion = f'prodes_{ecoregion}_20{year}.tif'\n",
    "\n",
    "    prodes_path = os.path.join(deforested_ecoregions, prodes_ecoregion)\n",
    "    gfc_path = os.path.join(deforested_ecoregions, gfc_ecoregion)\n",
    "\n",
    "    if os.path.exists(prodes_path):\n",
    "        print(f'{prodes_ecoregion} already exists.\\n')\n",
    "    else:\n",
    "        crop_to_ecoregion = f'gdalwarp -tr 0.0002689996094039614474 -0.0002690007898141364893 -cutline {shp_path} -crop_to_cutline -dstnodata 255 -of GTiff {prodes_yearly} prodes_temp.tif'\n",
    "        subprocess.run(crop_to_ecoregion, shell=True)\n",
    "\n",
    "        lzw_compress = f'gdal_translate -co COMPRESS=LZW prodes_temp.tif {prodes_path}'\n",
    "        subprocess.run(lzw_compress, shell=True)\n",
    "        os.remove('prodes_temp.tif')\n",
    "\n",
    "    if os.path.exists(gfc_path):\n",
    "        print(f'{gfc_ecoregion} already exists.\\n')\n",
    "    else:\n",
    "        crop_to_ecoregion = f'gdalwarp -tr 0.0002689996094039614474 -0.0002690007898141364893 -cutline {shp_path} -crop_to_cutline -dstnodata 255 -of GTiff {gfc_yearly} gfc_temp.tif'\n",
    "        subprocess.run(crop_to_ecoregion, shell=True)\n",
    "\n",
    "        lzw_compress = f'gdal_translate -co COMPRESS=LZW gfc_temp.tif {gfc_path}'\n",
    "        subprocess.run(lzw_compress, shell=True)\n",
    "        os.remove('gfc_temp.tif')\n",
    "\n",
    "    return prodes_path, gfc_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e2584995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to shared object (dynamically linked library)\n",
    "lib = ctypes.CDLL('./libsub_arrays.so')\n",
    "\n",
    "def analyze_ecoregion(ecoregion):\n",
    "    # Path to ecoregion shapefile\n",
    "    shp_path = os.path.join(ecoregions_dir, ecoregion)\n",
    "    \n",
    "    for year in years:\n",
    "        # Creates deforestation data of ecoregion \n",
    "        prodes_path, gfc_path = crop_ecoregion(shp_path, ecoregion, year)\n",
    "\n",
    "        # Extracting geotransform from PRODES deofrestation data\n",
    "        prodes_geotransform = get_geotransform_from_file(prodes_path)\n",
    "        prodes_x, prodes_pixel_width, _, prodes_y, _, prodes_pixel_height = prodes_geotransform\n",
    "        print(f'PRODES top left coordinate (lat, lon): {prodes_y}, {prodes_x}\\n')\n",
    "        \n",
    "        # Reading PRODES deforestation data\n",
    "        with rasterio.open(prodes_path) as prodes:\n",
    "                prodes_data = prodes.read(1)\n",
    "        print(f'prodes_data type: {prodes_data.dtype}\\n')\n",
    "        prodes_height, prodes_width = prodes_data.shape\n",
    "        \n",
    "        # Calculate coordinates of top right and bottom left corners\n",
    "        eco_top_right_lon = prodes_x + prodes_width * prodes_pixel_width\n",
    "        eco_top_right_lat = prodes_y\n",
    "        eco_bottom_left_lon = prodes_x\n",
    "        eco_bottom_left_lat = prodes_y + prodes_height * prodes_pixel_height\n",
    "\n",
    "        print(f'{ecoregion} Top Right Corner Coordinates (lat, lon): ({eco_top_right_lat}, {eco_top_right_lon})')\n",
    "        print(f'{ecoregion} Bottom Left Corner Coordinates (lat, lon): ({eco_bottom_left_lat}, {eco_bottom_left_lon})')\n",
    "        \n",
    "        # Reading Global Forest Change (GFC) deforestation data\n",
    "        with rasterio.open(gfc_path) as gfc:\n",
    "            gfc_data = gfc.read(1)\n",
    "        print(f'gfc_data type: {gfc_data.dtype}\\n')\n",
    "        \n",
    "        # Creating list of APPEARS tifs for the year sorted by day\n",
    "        if year < 10:\n",
    "            pattern = f'MOD13Q1.061__250m_16_days_EVI_doy200{year}*.tif'\n",
    "        else:\n",
    "            pattern = f'MOD13Q1.061__250m_16_days_EVI_doy20{year}*.tif'   \n",
    "        tifs = glob.glob(f'{APPEARS_dir}/{pattern}')\n",
    "        sorted_tifs = sorted(tifs, key=lambda x: int(x.split(\"_doy\")[1][:7]))\n",
    "        \n",
    "        # Extracting APPEARS tif geotransform \n",
    "        appears_geotransform = get_geotransform_from_file (sorted_tifs[0])\n",
    "        appears_x, appears_pixel_width, _, appears_y, _, appears_pixel_height = appears_geotransform\n",
    "        \n",
    "        # Calculate the pixel index for the top-left coordinate of the PRODES & GFC tif within the APPEARS tif\n",
    "        eco_top_left_x, eco_top_left_y = latlon_to_pixel(prodes_y, prodes_x, appears_geotransform)\n",
    "        print(f'{ecoregion} top left corner of index within APPEARS {eco_top_left_x}, {eco_top_left_y}')\n",
    "        \n",
    "        # Calculate the pixel index for the top-right coordinate of the PRODES & GFC tif within the APPEARS tif\n",
    "        eco_top_right_x, eco_top_right_y = latlon_to_pixel(eco_top_right_lat, eco_top_right_lon, appears_geotransform)\n",
    "        print(f'{ecoregion} top right corner of index within APPEARS {eco_top_right_x}, {eco_top_right_y}')\n",
    "        \n",
    "        # Calculate the pixel index for the bottom-left coordinate of the PRODES & GFC tif within the APPEARS tif\n",
    "        eco_bottom_left_x, eco_bottom_left_y = latlon_to_pixel(eco_bottom_left_lat, eco_bottom_left_lon, appears_geotransform)\n",
    "        print(f'{ecoregion} bottom left corner of index within APPEARS {eco_bottom_left_x}, {eco_bottom_left_y}\\n')\n",
    "        \n",
    "        # Keepts track of day within the year\n",
    "        day = 1\n",
    "        \n",
    "        # Boolean to check if an error occured reading the previous tif file\n",
    "        error = False\n",
    "        \n",
    "        prev = None\n",
    "        cur = None\n",
    "        max_drop = None\n",
    "        \n",
    "        for i, image in enumerate(sorted_tifs): # Processes all APPEARS tif files            \n",
    "            try: # Reading image\n",
    "                with rasterio.open(image) as appears:\n",
    "                    appears_data = appears.read(1)\n",
    "                \n",
    "                # Sets prev if it is day 1 or an error occured reading the previous tif file\n",
    "                if not prev or error: \n",
    "                    # Slicing APPEARS tif to ecoregion\n",
    "                    prev = appears_data[eco_top_left_y:eco_bottom_left_y+1, eco_top_left_x:eco_top_right_x+1]\n",
    "                    print(f'APPEARS slice dimensions: {prev.shape}')\n",
    "                    \n",
    "                    if day == 1:\n",
    "                        max_drop = np.zeros(prev.shape)\n",
    "                        \n",
    "                else:\n",
    "                    cur = appears_data[eco_top_left_y:eco_bottom_left_y+1, eco_top_left_x:eco_top_right_x+1]\n",
    "                    # convert to c_types\n",
    "                    # call c++ program\n",
    "                    # set prev equal to cur\n",
    "                    \n",
    "\n",
    "            except Exception as e: # Error with image\n",
    "                print(f\"Error reading data from {path}: {e}\")\n",
    "                # Continue to the next iteration\n",
    "            \n",
    "            day += 16\n",
    "            \n",
    "    print(f'Processed {ecoregion}!')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "c44cb445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GFC output file for year 16 already exists. Aborting.\n",
      "\n",
      "2016_prodes.tif already exists.\n",
      "\n",
      "The GFC output file for year 17 already exists. Aborting.\n",
      "\n",
      "2017_prodes.tif already exists.\n",
      "\n",
      "The GFC output file for year 18 already exists. Aborting.\n",
      "\n",
      "2018_prodes.tif already exists.\n",
      "\n",
      "The GFC output file for year 19 already exists. Aborting.\n",
      "\n",
      "2019_prodes.tif already exists.\n",
      "\n",
      "The GFC output file for year 20 already exists. Aborting.\n",
      "\n",
      "2020_prodes.tif already exists.\n",
      "\n",
      "The GFC output file for year 21 already exists. Aborting.\n",
      "\n",
      "2021_prodes.tif already exists.\n",
      "\n",
      "The GFC output file for year 22 already exists. Aborting.\n",
      "\n",
      "2022_prodes.tif already exists.\n",
      "\n",
      "prodes_Mato_Grosso_seasonal_forests.shp_2016.tif already exists.\n",
      "\n",
      "gfc_Mato_Grosso_seasonal_forests.shp_2016.tif already exists.\n",
      "\n",
      "PRODES top left coordinate (lat, lon): -5.20221408717634, -59.35693748205469\n",
      "\n",
      "prodes_data type: uint8\n",
      "\n",
      "Mato_Grosso_seasonal_forests.shp Top Right Corner Coordinates (lat, lon): (-5.20221408717634, -47.834339213236)\n",
      "Mato_Grosso_seasonal_forests.shp Bottom Left Corner Coordinates (lat, lon): (-13.63216083837175, -59.35693748205469)\n",
      "gfc_data type: uint8\n",
      "\n",
      "Mato_Grosso_seasonal_forests.shp top left corner of index within APPEARS 7020, 5027\n",
      "Mato_Grosso_seasonal_forests.shp top right corner of index within APPEARS 12551, 5027\n",
      "Mato_Grosso_seasonal_forests.shp bottom left corner of index within APPEARS 7020, 9073\n",
      "\n",
      "APPEARS slice dimensions: (4047, 5532)\n",
      "max_drop dimensions: (4047, 5532)\n",
      "Error reading data from /Users/davidcastrejon/Documents/Amazon_Rainforest/Data/APPEARS/EVI/2015-2023-EVI/MOD13Q1.061__250m_16_days_EVI_doy2017129_aid0001.tif: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "Error reading data from /Users/davidcastrejon/Documents/Amazon_Rainforest/Data/APPEARS/EVI/2015-2023-EVI/MOD13Q1.061__250m_16_days_EVI_doy2017129_aid0001.tif: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "Error reading data from /Users/davidcastrejon/Documents/Amazon_Rainforest/Data/APPEARS/EVI/2015-2023-EVI/MOD13Q1.061__250m_16_days_EVI_doy2017129_aid0001.tif: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[378], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     29\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 30\u001b[0m \u001b[43manalyze_ecoregion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecoregion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal time to process \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mecoregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[377], line 74\u001b[0m, in \u001b[0;36manalyze_ecoregion\u001b[0;34m(ecoregion)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;66;03m# Reading image\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m rasterio\u001b[38;5;241m.\u001b[39mopen(image) \u001b[38;5;28;01mas\u001b[39;00m appears:\n\u001b[0;32m---> 74\u001b[0m         appears_data \u001b[38;5;241m=\u001b[39m \u001b[43mappears\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# Sets prev if it is day 1 or an error occured reading the previous tif file\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prev \u001b[38;5;129;01mor\u001b[39;00m error: \n\u001b[1;32m     78\u001b[0m         \u001b[38;5;66;03m# Slicing APPEARS tif to ecoregion\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    for year in years:\n",
    "        merge_tiles(year)\n",
    "        \n",
    "        if year < 10:\n",
    "            prodes_interm = f'200{year}_prodes_interm.tif'\n",
    "            prodes_yearly = f'200{year}_prodes.tif'\n",
    "        else:\n",
    "            prodes_interm = f'20{year}_prodes_interm.tif'\n",
    "            prodes_yearly = f'20{year}_prodes.tif'\n",
    "            \n",
    "        if os.path.exists(os.path.join(working_dir, prodes_yearly)):\n",
    "            print(f'{prodes_yearly} already exists.\\n')\n",
    "        else:\n",
    "            # Create prodes_yearly raster if it does not already exist\n",
    "            extract_year = f'gdal_calc.py -A {PRODES} --outfile={prodes_interm} --calc=\"A=={year}\" --NoDataValue=255'\n",
    "            subprocess.run(extract_year, shell=True)\n",
    "            \n",
    "            lzw_compress = f'gdal_translate -co COMPRESS=LZW {prodes_interm} {prodes_yearly}'\n",
    "            subprocess.run(lzw_compress, shell=True)\n",
    "            \n",
    "            os.remove(prodes_interm)\n",
    "            \n",
    "    count = 0\n",
    "    for ecoregion in ecoregions:\n",
    "        if count == 3:\n",
    "            break\n",
    "        start = time.time()\n",
    "        analyze_ecoregion(ecoregion)\n",
    "        end = time.time()\n",
    "        print(f'Total time to process {ecoregion}: {end - start}')\n",
    "        count += 1\n",
    "            \n",
    "    '''\n",
    "    with Pool() as pool:\n",
    "        pool.map(analyze_ecoregions, ecoregions)\n",
    "        pool.join\n",
    "    '''        \n",
    "         \n",
    "    print('\\nFinished!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c603f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7477a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
